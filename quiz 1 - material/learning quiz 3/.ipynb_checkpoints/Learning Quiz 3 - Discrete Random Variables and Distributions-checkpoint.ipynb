{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Random Variables \n",
    "\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "\n",
    "1.  Know the definition  of a discrete  random  variable.\n",
    "\n",
    "2.  Know the  Bernoulli,  binomial,  and  geometric  distributions and  examples  of what  they model.\n",
    "\n",
    "3.  Be able to describe  the  probability mass function  and  cumulative distribution function using tables  and formulas.\n",
    "\n",
    "4.  Be able to construct new random  variables  from old ones.\n",
    "\n",
    "5.  Know how to compute  expected  value (mean).\n",
    "\n",
    "\n",
    "##    Random Variables\n",
    "\n",
    "\n",
    "This quiz is largely about  testing your knowledge for some useful terminology,  building  on the notions  of sample space and probability function.  The key words are\n",
    "\n",
    "1.  Random  variable\n",
    "\n",
    "2.  Probability mass function  (pmf)\n",
    "\n",
    "3.  Cumulative distribution function  (cdf)\n",
    "\n",
    "\n",
    "2.1     Recall\n",
    "\n",
    "A discrete sample space $\\Omega$ is a finite or listable set of outcomes $\\left\\{\\omega_{1}, \\omega_{2} \\ldots\\right\\}$. The probability of an outcome $\\omega$ is denoted $P(\\omega)$. An event $E$ is a subset of $\\Omega .$ The probability of an event $E$ is $P(E)=\\sum_{\\omega \\in E} P(\\omega) .$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2.2     Random variables as  payoff functions\n",
    "\n",
    "\\begin{exercise}\n",
    "\n",
    "Roll a die twice and record the outcomes  as (i, j), where i is the result  of the first roll and\n",
    "j the result  of the second. \n",
    "\n",
    "a) What is the sample space?\n",
    "\n",
    "b) What is the probability function $P(i,j)$?\n",
    "\n",
    "In this  game,  you win $500 if the  sum is 7 and  lose $100 otherwise.   We give this  payoff function  the name X  and describe it formally by \n",
    "\n",
    "$$\n",
    "X(i, j)=\\left\\{\\begin{array}{ll}\n",
    "500 & \\text { if } i+j=7 \\\\\n",
    "-100 & \\text { if } i+j \\neq 7\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "If we change the game by using the payoff function \n",
    "\n",
    "$$\n",
    "Y(i, j)=i j-10\n",
    "$$\n",
    "\n",
    "c) which game is better??\n",
    "\n",
    "\\end{exercise}\n",
    "\n",
    "\n",
    "These  payoff  functions  are  examples  of random  variables.  <font color='blue'> A random  variable  assigns  a number  to each outcome  in a sample space </font>.  More formally:\n",
    "\n",
    "\\begin{definition}\n",
    "Let $\\Omega$ be a sample space. A discrete random variable is a function\n",
    "$$\n",
    "X: \\Omega \\rightarrow \\mathbf{R}\n",
    "$$\n",
    "that takes a discrete set of values. (Recall that $\\mathbf{R}$ stands for the real numbers.)\n",
    "\\end{definition}\n",
    "\n",
    "\n",
    "Why is X  called a random  variable?  It's `random` because its value depends  on a random outcome  of an experiment.  And we treat X  like we would a usual  variable:  we can add it to other  random  variables,  square it, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events and random variables\n",
    "\n",
    "For  any  value  $a$  we write  $<font color='blue'> X  = a </font>$ to  mean  the  <font color='blue'>event</font>  consisting  of all  outcomes $\\omega$  with $X(\\omega) = a$.\n",
    "\n",
    "\\begin{exercise}\n",
    "In the previous exercise we rolled two dice and defined the payoff function X (which is a random variable)\n",
    "\n",
    "a) What is the event <font color='blue'>$X = 500$</font>?\n",
    "\n",
    "b) what is the $P(X = 500)$?\n",
    "\n",
    "c) What is the event $X = 1000$ and its probability $P(X = 1000)$?\n",
    "\n",
    "\\end{exercise}\n",
    "\n",
    "\n",
    "Example 3.  In Example  1 we rolled two dice and X  was the random  variable\n",
    " \n",
    "\n",
    "\n",
    "## Probability mass function and cumulative distribution function\n",
    "\n",
    "\n",
    "\\begin{definition}\n",
    "\n",
    "The <font color='blue'>probability mass function (pmf)</font> of a discrete random variable is the function $p(a)=P(X=a)$\n",
    "Note:\n",
    "\n",
    "1. We always have $0 \\leq p(a) \\leq 1$.\n",
    "\n",
    "2. We allow $a$ to be any number. If $a$ is a value that $X$ never takes, then $p(a)=0$.\n",
    "\n",
    "\\end{definition}\n",
    "\n",
    "\n",
    "\\begin{exercise}\n",
    "Let  $\\Omega$ be our  earlier  sample  space  for rolling  2 dice.   Define  the  random variable  $M$  to be the maximum  value of the two dice:\n",
    "\n",
    "$$M(i, j) = max(i, j)$$.\n",
    "\n",
    "For example,  the roll (3,5) has maximum  5, i.e. M(3, 5) = 5.\n",
    "\n",
    "a) What are the values of $p(a)$ for $a = 1, 2, 3, 4, 5, 6$\n",
    "\n",
    "b) What  is $p(8)$?\n",
    "\n",
    "\\end{exercise}\n",
    "\n",
    "\n",
    "\n",
    "## Events and inequalities\n",
    "\n",
    "Inequalities  with  random  variables  describe  events.   For  example  $X  \\le a$ is the  set  of all outcomes  $\\omega$ such that $X(\\omega) \\le a$.\n",
    "\n",
    "\\begin{exercise}\n",
    "If our sample space is the set of all pairs of $(i, j)$ coming from rolling two dice and $Z(i, j) = i + j$ is the sum of the dice then \n",
    "\n",
    "What is the set $Z \\le 4$?\n",
    "\\end{exercise}\n",
    "\n",
    "\n",
    "\n",
    "## The cumulative distribution function (cdf)\n",
    "\n",
    "\\begin{definition}\n",
    "The  <font color='blue'>cumulative distribution  function  (cdf)</font>  of a  random  variable  $X$  is the function  $F$  given by $F(a) = P (X \\le a)$.  We will often shorten  this to <font color='blue'>distribution function</font>.\n",
    "\n",
    "Note  that the  definition  of $F(a)$  uses the symbol  less than  <font color='orange'>or  equal</font>.   This  will be important for getting your calculations  exactly  right.\n",
    "\\end{definition}\n",
    "\n",
    "\n",
    "\\begin{example}\n",
    "Continuing with the previously defined random variable  M, we have\n",
    "\n",
    "\\begin{array}{rlcccccc}\n",
    "\\text { value } & a: & 1 & 1 & 3 & 4 & 5 & 6 \\\\\n",
    "\\text { pmf } & p(a): & 1 / 36 & 3 / 36 & 5 / 36 & 7 / 36 & 9 / 36 & 11 / 36 \\\\\n",
    "\\text { cdf } & F(a): & 1 / 36 & 4 / 36 & 9 / 36 & 16 / 36 & 25 / 36 & 36 / 36\n",
    "\\end{array}\n",
    "\n",
    "\\end{example}\n",
    "\n",
    "\n",
    "$F(a)$ is called the **cumulative** distribution function  because $F(a)$ gives the total  probability that accumulates by adding up the probabilities $p(b)$ as $b$ runs from $−infty$ to $a$.  For example, in the table  above, the entry  $16/36$ in column 4 for the cdf is the sum of the values of the pmf from column 1 to column 4. In notation:\n",
    "\n",
    "As events: $M \\leq 4 =\\{1,2,3,4\\} ; $F(4)=P(M \\leq 4)=1/36+3/36+5/36+7/36=16 / 36$\n",
    "\n",
    "Just  like the  probability mass  function,  $F(a)$  is defined  for all  values  a.   In  the  above example,  $F(8)=1, F(-2)=0, F(2.5)=4/36,$ and $F(\\pi)=9/36$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs of $p(a)$  and $F(a)$\n",
    "\n",
    "We can visualize the pmf and cdf with graphs.  For example,  let $X$ be the number  of heads in 3 tosses of a fair coin:\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "&\\begin{array}{ccccc}\n",
    "\\text { value } a: & 0 & 1 & 2 & 3 \\\\\n",
    "\\operatorname{pmf} p(a): & 1 / 8 & 3 / 8 & 3 / 8 & 1 / 8 \\\\\n",
    "\\operatorname {cdf } F(a): & 1 / 8 & 4 / 8 & 7 / 8 & 1\n",
    "\\end{array}\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "The colored graphs show how the cumulative distribution function is built by accumulating\n",
    "probability as a increases.  The black and white graphs are the more standard presentations.\n",
    "\n",
    "![graphs](pmf_pcf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{exercise}\n",
    "Plot the pmf and cdf for the maximum of two  dice exercise.\n",
    "\\end{exercise}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Properties of the cdf $F$ \n",
    "\n",
    "The cdf $F$  of a random  variable  satisfies several properties:\n",
    "\n",
    "1.  $F$  is **non-decreasing**.  That is, its graph never goes down, or symbolically if $a \\le b$ then $F(a) \\le F(b)$.\n",
    "\n",
    "2.  $0 \\le F(a) \\le 1$.\n",
    "\n",
    "3.  $\\lim _{a \\rightarrow \\infty} F(a)=1, \\quad \\lim _{a \\rightarrow-\\infty} F(a)=0$\n",
    "\n",
    "In  words,  (1)  says  the  cumulative probability  $F(a)$  increases  or  remains  constant  as  $a$ increases,  but never  decreases;  (2)  says the  accumulated probability is always  between  0 and 1; (3) says that as a gets very large, it becomes more and more certain  that $X \\le a$ and as a gets very negative  it becomes more and more certain  that $X > a$.\n",
    "\n",
    "\\begin{exercise}\n",
    "Why does a cdf satisfy each of these properties?\n",
    "\\end{exercise}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Distributions\n",
    "\n",
    "\n",
    "### Bernoulli Distributions\n",
    "\n",
    "**Model**:  The  Bernoulli  distribution models one trial  in an  experiment that can  result  in either  **success** or **failure**  This  is the  most  important distribution and it is also the  simplest.   A random  variable  $X$  has a Bernoulli distribution with parameter $p$ if: \n",
    "\n",
    "\n",
    "1.  $X$  takes  the values 0 and 1.\n",
    "\n",
    "2. $P(X=1)=p$ and $P(X=0)=1-p$.\n",
    "\n",
    "We will write $X \\sim$ Bernoulli $(p)$ or $\\operatorname{Ber}(p)$, which is read **“X  follows a Bernoulli distribution with parameter p”** or **“X  is drawn  from a Bernoulli  distribution with parameter p”**.\n",
    "\n",
    "A simple model for the  Bernoulli  distribution is to flip a coin with  probability $p$ of heads, with  $X  = 1$ on heads  and  $X  = 0$ on tails.   The  general  terminology  is to  say $X$  is 1 on success and 0 on failure, with success and failure defined by the context.\n",
    "\n",
    "Many decisions can be modeled as a binary  choice, such as votes for or against  a proposal. If $p$ is the proportion of the voting population that favors the proposal,  than  the vote of a random  individual  is modeled by a _Bernoulli(p)_.\n",
    "\n",
    "Here are the  table  and  graphs  of the  pmf and  cdf for the  Bernoulli(1/2) distribution and below that for the general Bernoulli(p)  distribution.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "3.2     Binomial Distributions\n",
    "\n",
    "The binomial  distribution Binomial(n,p), or Bin(n,p), models the number  of successes in n\n",
    "independent Bernoulli(p)  trials.\n",
    "\n",
    "There  is a hierarchy  here.   A single Bernoulli  trial  is, say,  one toss  of a coin.   A single binomial  trial  consists of n Bernoulli trials.  For coin ﬂips the sample space for a Bernoulli trial  is {H, T }. The sample space for a binomial  trial  is all sequences of heads and tails of length n.  Likewise a Bernoulli random  variable takes values 0 and 1 and a binomial random variables  takes  values 0, 1, 2, . . . , n.\n",
    "\n",
    "Example 6.  Binomial(1,p)  is the same as Bernoulli(p). \n",
    "\n",
    "\n",
    "Example 7.  The number  of heads in n ﬂips of a coin with probability p of heads follows a Binomial(n, p) distribution.\n",
    "We describe X ∼ Binomial(n, p) by giving its values and probabilities. For notation we will use k to mean an arbitrary number  between  0 and n.\n",
    "n \n",
    "We remind  you that ‘n choose k =\n",
    "k\n",
    " \n",
    "= nCk is the  number  of ways to choose k things \n",
    "out of a collection of n things  and it has the formula\n",
    "\n",
    "\n",
    "k        k! (n − k)!\n",
    "\n",
    "(It is also called a binomial coeﬃcient.)  Here is a table for the pmf of a Binomial(n, k) ran­ dom variable.  We will explain how the binomial  coeﬃcients enter  the pmf for the binomial distribution after a simple example.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1                                2                                         k\n",
    "\n",
    "\n",
    "Example 8.  What  is the probability of 3 or more heads in 5 tosses of a fair coin?\n",
    "\n",
    "answer: The binomial  coeﬃcients associated  with n = 5 are \n",
    "\n",
    "5\n",
    "= 1,\n",
    " \n",
    "\n",
    "5         5!\n",
    "=\n",
    " \n",
    "\n",
    "5 · 4 · 3 · 2 · 1\n",
    " \n",
    "\n",
    "5         5!\n",
    "=\n",
    " \n",
    "\n",
    "5 · 4 · 3 · 2 · 1      5 · 4 \n",
    "0                  1        1! 4!        4 · 3 · 2 · 1                  2        2! 3!     2 · 1 · 3 · 2 · 1        2\n",
    "\n",
    "and similarly\n",
    "5                    5                  5\n",
    "= 10,             = 5,             = 1.\n",
    "3                    4                  5\n",
    "Using these values we get the following table  for X ∼ Binomial(5,p).\n",
    "\n",
    "values a:          0                 1                     2                       3                     4             5 pmf p(a):     (1 − p)5      5p(1 − p)4      10p2(1 − p)3      10p3(1 − p)2      5p4(1 − p)    p5\n",
    "\n",
    "We were told p = 1/2 so \n",
    "\n",
    "1   3     1   2\n",
    " \n",
    "\n",
    "1   4     1   1\n",
    " \n",
    "\n",
    "1   5          16       1 \n",
    "P (X ≥ 3) = 10   2         2     + 5   2         2     +   2\n",
    " \n",
    "=      =   .\n",
    "32       2 \n",
    "\n",
    "Think: Why is the value of 1/2  not surprising?\n",
    "\n",
    "\n",
    "3.3     Explanation of the binomial probabilities\n",
    "\n",
    "For concreteness,  let n = 5 and k = 2 (the  argument for arbitrary n and k is identical.)  So X ∼ binomial(5, p) and we want to compute  p(2).  The long way to compute  p(2) is to list all the  ways to get exactly  2 heads  in 5 coin ﬂips and  add  up their  probabilities.  The  list has 10 entries:\n",
    "HHTTT, HTHTT, HTTHT, HTTTH, THHTT, THTHT, THTTH, TTHHT, TTHTH, TTTHH \n",
    "\n",
    "\n",
    "Each entry  has the same probability of occurring,  namely\n",
    "\n",
    "p2(1 − p)3.\n",
    "\n",
    "This is because each of the  two heads has probability p and each of the  3 tails  has proba­ bility  1 − p.  Because  the  individual  tosses are independent  we can multiply  probabilities. Therefore,  the  total  probability of exactly  2 heads is the  sum of 10 identical  probabilities, i.e.    p(2) = 10p2(1 − p)3,   as shown in the table.\n",
    "\n",
    "This guides us to the shorter  way to do the computation. We have to count the number  of sequences with  exactly  2 heads.  To do this  we need to choose 2 of the  tosses to be heads and  the  remaining  3 to be tails.  The  number  of such sequences is the  number  of ways to \n",
    "choose 2 out  of 5 things,  that is T5\n",
    " \n",
    ".  Since each such sequence  has the  same probability, \n",
    "p2(1 − p)3, we get the probability of exactly  2 heads p(2) = T5\n",
    " \n",
    "p2(1 − p)3. \n",
    "\n",
    "Here are some binomial probability mass function  (here, frequency is the same as probabil­\n",
    "ity).\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "3.4     Geometric Distributions\n",
    "\n",
    "A geometric  distribution models the  number  of tails  before the  ﬁrst  head  in a sequence of coin ﬂips (Bernoulli  trials).\n",
    "Example 9.  (a) Flip a coin repeatedly. Let X be the number  of tails before the ﬁrst heads. So, X can equal 0, i.e. the ﬁrst ﬂip is heads,  1, 2, . . . . In principle  it take  any nonnegative integer  value.\n",
    "(b) Give a ﬂip of tails the value 0, and heads the value 1. In this case, X  is the number  of\n",
    "0’s before the ﬁrst 1. \n",
    "\n",
    "\n",
    "(c) Give a ﬂip of tails the value 1, and heads the value 0. In this case, X  is the number  of\n",
    "1’s before the ﬁrst 0.\n",
    "\n",
    "(d) Call a ﬂip of tails a success and heads a failure.  So, X is the number  of successes before the ﬁrst failure.\n",
    "(e) Call a ﬂip of tails a failure and heads a success.  So, X  is the number  of failures before the ﬁrst success.\n",
    "You can see this models many  diﬀerent scenarios  of this  type.  The most neutral language is the number  of tails before the ﬁrst head.\n",
    "Formal deﬁnition. The random  variable  X follows a geometric distribution with param­\n",
    "eter p if\n",
    "\n",
    "• X  takes  the values 0, 1, 2, 3, . . .\n",
    "\n",
    "• its pmf is given by p(k) = P (X = k) = (1 − p)kp.\n",
    "\n",
    "We denote  this by X ∼ geometric(p)  or geo(p).  In table  form we have:\n",
    "\n",
    "value\ta:\t0\t1\t2\t3\t. . .\tk\t. . .\n",
    "pmf\tp(a):\tp\t(1 − p)p\t(1 − p)2p\t(1 − p)3p\t. . .\t(1 − p)kp\t. . .\n",
    "Table:  X ∼ geometric(p):  X = the number  of 0s before the ﬁrst 1. We will show how this table  was computed  in an example below.\n",
    "The  geometric  distribution is an example  of a discrete  distribution that takes  an inﬁnite number  of possible  values.   Things  can  get  confusing  when  we work  with  successes and failure since we might want to model the number  of successes before the ﬁrst failure or we might want the number  of failures before the ﬁrst success.  To keep straight things straight you can translate to the neutral language  of the number  of tails before the ﬁrst heads.\n",
    "\n",
    "1\n",
    "\n",
    " \n",
    "0.4\n",
    " \n",
    "0.8 \n",
    "\n",
    " \n",
    "0.3\n",
    " \n",
    "0.6 \n",
    "\n",
    " \n",
    "0.2\n",
    " \n",
    "0.4 \n",
    "\n",
    " \n",
    "0.1\n",
    " \n",
    "0.2 \n",
    " \n",
    "0.0\n",
    " \n",
    "a\n",
    "0   1                    5                         10\n",
    " \n",
    "0.0\n",
    " \n",
    "a\n",
    "0   1                    5                         10 \n",
    "\n",
    "pmf and cdf  for  the geometric(1/3) distribution\n",
    "\n",
    "Example 10.    Computing geometric  probabilities.  Suppose  that the  inhabitants of an island plan their families by having babies until the ﬁrst girl is born.  Assume the probability of having a girl with each pregnancy  is 0.5 independent of other pregnancies,  that all babies survive and there  are no multiple  births.  What  is the probability that a family has k boys? \n",
    "\n",
    "\n",
    "answer: In neutral language  we can  think  of boys as tails  and  girls as heads.   Then  the number  of boys in a family is the number  of tails before the ﬁrst heads.\n",
    "Let’s practice  using standard notation to present this.  So, let X  be the number  of boys in a (randomly-chosen) family.  So, X  is a geometric  random  variable.   We are asked to ﬁnd p(k) = P (X = k).  A family has k boys if the sequence of children  in the family from oldest to youngest is\n",
    "BBB . . . BG\n",
    "\n",
    "with  the  ﬁrst  k children  being boys.  The  probability of this  sequence  is just  the  product of the probability for each child, i.e.  (1/2)k  · (1/2) = (1/2)k+1.  (Note:  The assumptions of equal probability and independence  are simpliﬁcations  of reality.)\n",
    "\n",
    "Think: What  is the ratio  of boys to girls on the island?\n",
    "\n",
    "More geometric confusion.  Another  common deﬁnition  for the geometric distribution is the number  of tosses until  the  ﬁrst  heads.   In this  case X  can take  the  values 1, i.e.  the  ﬁrst ﬂip is heads,  2, 3, . . . . This is just  our geometric  random  variable  plus 1. The methods  of computing  with it are just  like the ones we used above.\n",
    "\n",
    "\n",
    "3.5     Uniform Distribution\n",
    "\n",
    "The uniform distribution models any situation where all the outcomes  are equally likely.\n",
    "\n",
    "X ∼ uniform(N).\n",
    "\n",
    "X takes values 1, 2, 3, . . . , N, each with probability 1/N.  We have already seen this distribu­\n",
    "tion many times when modeling to fair coins (N  = 2), dice (N  = 6), birthdays (N  = 365),\n",
    "and poker hands  (N  = T52 ).\n",
    "\n",
    "\n",
    "3.6     Discrete Distributions Applet\n",
    "\n",
    "The applet at http://mathlets.org/mathlets/probability-distributions/ gives a dy­ namic  view of some discrete  distributions.  The  graphs  will change  smoothly  as you move the various sliders.  Try  playing with the diﬀerent distributions and parameters.\n",
    "\n",
    "This applet  is carefully color-coded.  Two things  with the same color represent the same or closely related  notions.  By understanding the color-coding and other  details  of the applet, you will acquire a stronger  intuition for the distributions shown.\n",
    "\n",
    "\n",
    "3.7     Other Distributions\n",
    "\n",
    "There  are a million other  named  distributions arising is various  contexts.  We don’t expect you  to  memorize  them  (we certainly  have  not!),  but  you  should  be comfortable  using  a resource like Wikipedia  to look up a pmf.  For example,  take  a look at  the info box at  the top  rightof http://en.wikipedia.org/wiki/Hypergeometric_distribution.   The  info box lists many (surely  unfamiliar) properties  in addition  to the pmf. \n",
    "\n",
    "\n",
    "4    Arithmetic with Random Variables\n",
    "\n",
    "We can do arithmetic with random  variables.  For example,  we can add subtract, multiply or square them.\n",
    "There  is a simple,  but  extremely  important idea  for counting.   It  says that if we have  a sequence of numbers  that are either  0 or 1 then  the  sum of the  sequence is the  number  of\n",
    "1s.\n",
    "\n",
    "Example 11.  Consider  the sequence with ﬁve 1s\n",
    "\n",
    "1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0.\n",
    "\n",
    "It is easy to see that the sum of this sequence is 5 the number  of 1s.\n",
    "\n",
    "We illustrates this idea by counting  the number  of heads in n tosses of a coin.\n",
    "\n",
    "Example 12.   Toss a fair coin n times.  Let Xj   be 1 if the  jth toss is heads  and  0 if it’s tails.  So, Xj  is a Bernoulli(1/2) random  variable.   Let X  be the  total  number  of heads  in the  n tosses.  Assuming  the  tosses are independence  we know X  ∼ binomial(n, 1/2).   We can also write\n",
    "X = X1  + X2  + X3  + . . . + Xn.\n",
    "\n",
    "Again, this is because the terms  in the sum on the right are all either  0 or 1.  So, the sum is exactly  the number  of Xj  that are 1, i.e. the number  of heads.\n",
    "The important thing to see in the example above is that we’ve written  the more complicated binomial  random  variable  X  as the  sum  of extremely  simple random  variables  Xj.   This will allow us to manipulate X  algebraically.\n",
    "\n",
    "Think: Suppose X and Y  are independent and X ∼ binomial(n, 1/2) and Y  ∼ binomial(m, 1/2). What  kind of distribution does X + Y  follow? (Answer: binomial(n + m, 1/2).  Why?)\n",
    "\n",
    "Example 13.    Suppose  X  and  Y   are  independent random  variables  with  the  following tables.\n",
    "\n",
    "Values of X\tx:\t1\t2\t3\t4\t\n",
    "pmf\tpX(x):\t1/10\t2/10\t3/10\t4/10\t\n",
    "\n",
    "Values of Y\t\n",
    "y:\t\n",
    "1\t\n",
    "2\t\n",
    "3\t\n",
    "4\t\n",
    "5\n",
    "pmf\tpY (y):\t1/15\t2/15\t3/15\t4/15\t5/15\n",
    "Check that the total  probability for each random  variable is 1. Make a table for the random variable  X + Y .\n",
    "answer: The ﬁrst thing to do is make a two-dimensional table for the product  sample space consisting  of pairs  (x, y), where x is a possible value of X  and y one of Y .  To help do the computation, the  probabilities for the  X  values are put  in the  far right column and  those for Y  are in the  bottom row.  Because X  and Y  are independent the  probability for (x, y) pair is just  the product  of the individual  probabilities. \n",
    "\n",
    "\n",
    "Y  values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1                                                                                                 1/10\n",
    "\n",
    "\n",
    "\n",
    "2                                                                                                 2/10\n",
    "\n",
    "\n",
    "\n",
    "3                                                                                                 3/10\n",
    "\n",
    "\n",
    "\n",
    "4                                                                                                 4/10\n",
    "\n",
    "\n",
    "\n",
    "1/15         2/15         3/15         4/15         5/15\n",
    "\n",
    "The diagonal  stripes  show sets of squares  where X + Y  is the  same.  All we have to do to compute  the probability table  for X + Y  is sum the probabilities for each stripe.\n",
    "\n",
    "X + Y  values:        2            3             4              5              6              7              8              9 \n",
    "pmf:             1/150    4/150    10/150    20/150    30/150    34/150    31/150    20/150 \n",
    "\n",
    "When the tables  are too big to write down we’ll need to use purely algebraic  techniques  to compute  the probabilities of a sum.  We will learn how to do this in due course. \n",
    "MIT OpenCourseWare https://ocw.mit.edu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "18.05 Introduction to Probability and Statistics\n",
    "Spring 2014\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 4.0.2",
   "language": "R",
   "name": "ir40"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
